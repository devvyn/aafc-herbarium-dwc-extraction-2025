# AAFC Herbarium Darwin Core Extraction

**Production-ready toolkit for extracting Darwin Core metadata from herbarium specimen images**

[![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)](https://github.com/devvyn/aafc-herbarium-dwc-extraction-2025/releases)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

## ğŸ¯ What This Does

Automatically extracts structured biodiversity data from herbarium specimen photographs using OCR and AI:

- **Reads labels** (handwritten & printed) from specimen images
- **Extracts Darwin Core fields** (scientific name, location, date, collector, etc.)
- **Outputs standardized data** ready for GBIF publication
- **Provides review tools** for quality validation

### Example Workflow

```
ğŸ“· Herbarium Photo â†’ ğŸ¤– AI Extraction â†’ ğŸ“Š Darwin Core CSV â†’ ğŸŒ GBIF Publication
```

**Input:** Herbarium specimen image
**Output:** Structured database record

```csv
catalogNumber,scientificName,eventDate,recordedBy,locality,stateProvince,country
"019121","Bouteloua gracilis (HBK.) Lag.","1969-08-14","J. Looman","Beaver River crossing","Saskatchewan","Canada"
```

## ğŸš€ Quick Start

```bash
# Install
git clone https://github.com/devvyn/aafc-herbarium-dwc-extraction-2025.git
cd aafc-herbarium-dwc-extraction-2025
./bootstrap.sh

# Process specimens
python cli.py process --input photos/ --output results/

# Review results
python review_web.py --db results/candidates.db --images photos/
```

## ğŸ“¦ Current Release: v1.0.0

**Production dataset:** 2,885 herbarium specimens extracted
**Method:** Apple Vision API (FREE) + rules engine
**Darwin Core fields:** 7 core terms
**Cost:** $0

### v1.0 Deliverables

ğŸ“ **Dataset:** `deliverables/v1.0_vision_api_baseline.jsonl`
ğŸ“Š **Validation:** 20-specimen ground truth sample
ğŸ“ˆ **Quality metrics:** Documented accuracy baselines
ğŸ“š **Documentation:** Complete extraction methodology

See [deliverables/README.md](deliverables/README.md) for details.

### âš¡ v2.0 Coming Soon (In Progress)

**Enhanced extraction** with GPT-4o-mini:
- ğŸ”¢ **16 Darwin Core fields** (9 additional: habitat, elevation, recordNumber, etc.)
- ğŸ¯ **Layout-aware prompts** (TOP vs BOTTOM label distinction)
- ğŸ“Š **Expected quality:** ~70% accuracy (vs ~15% baseline)
- ğŸ’° **Cost:** $1.60 total or FREE overnight (15-20 hours)

**Agent orchestration framework:** "Consider all means accessible"
- ğŸ¤– **Pipeline composer** with cost/quality optimization
- ğŸ’¸ **FREE-first routing** with paid fallback strategies
- ğŸ”¬ **Ensemble voting** for research-grade quality
- ğŸ“ˆ **Progressive enhancement** (free baseline + selective paid)

See [agents/README.md](agents/README.md) for architecture details.

## ğŸ”§ Installation

### Requirements
- Python 3.11+
- macOS (Apple Vision OCR) or Linux/Windows (cloud APIs)

### Setup

```bash
# Clone repository
git clone https://github.com/devvyn/aafc-herbarium-dwc-extraction-2025.git
cd aafc-herbarium-dwc-extraction-2025

# Install dependencies
./bootstrap.sh

# Check available OCR engines
python cli.py check-deps
```

### macOS (Recommended)
âœ… Apple Vision API works out-of-the-box (FREE, no API keys)

### Windows/Linux
Requires cloud API keys. Copy `.env.example` to `.env` and configure:

```bash
# OpenAI (GPT-4o-mini for direct extraction)
OPENAI_API_KEY="your-key-here"

# Optional: Anthropic Claude, Google Gemini
# ANTHROPIC_API_KEY=""
# GOOGLE_API_KEY=""
```

See [API_SETUP_QUICK.md](API_SETUP_QUICK.md) for detailed setup.

## ğŸ’¡ Core Features

### Multi-Engine OCR Support

| Engine | Platform | Cost/1000 | Quality | Notes |
|--------|----------|-----------|---------|-------|
| **Apple Vision** | macOS | FREE | Medium | Best for macOS users |
| **GPT-4o-mini** | All | $1.60 | High | Layout-aware, 16 fields |
| **Tesseract** | All | FREE | Low | Fallback option |
| **Azure Vision** | All | $1.00 | Medium | Cloud alternative |

### Intelligent Pipeline Composition

**Agent-managed optimization:**
- ğŸ†“ **Zero budget:** Vision API â†’ Rules engine (7 fields)
- ğŸ’° **$1.60 budget:** GPT-4o-mini direct (16 fields, 2 hours)
- ğŸ”¬ **Research-grade:** Multi-engine ensemble voting (~$10)

See [agents/pipeline_composer.py](agents/pipeline_composer.py) for decision logic.

### Darwin Core Output

**v1.0 Fields (7):**
- catalogNumber, scientificName, eventDate, recordedBy
- locality, stateProvince, country

**v2.0 Fields (16):**
*All v1.0 fields plus:*
- habitat, minimumElevationInMeters, recordNumber
- identifiedBy, dateIdentified, verbatimLocality
- verbatimEventDate, verbatimElevation, associatedTaxa

### Review & Validation Tools

**Web interface** (recommended):
```bash
python review_web.py --db results/candidates.db --images photos/
```

**Terminal interface:**
```bash
python herbarium_ui.py --tui
```

## ğŸ“Š Data Publication

Ready to publish extracted data to GBIF via Canadensys:

1. **Export Darwin Core Archive:**
   ```bash
   python scripts/export_dwc_archive.py \
     --input deliverables/v1.0_vision_api_baseline.jsonl \
     --output dwc-archive/occurrence.txt
   ```

2. **Generate EML metadata:**
   ```bash
   python scripts/generate_eml.py \
     --title "AAFC Herbarium - Saskatchewan Flora" \
     --license CC0
   ```

3. **Upload to Canadensys IPT** (browser-based, no installation)

4. **Automatic GBIF publication** (24-48 hours)

See [docs/DATA_PUBLICATION_GUIDE.md](docs/DATA_PUBLICATION_GUIDE.md) for complete workflow.

## ğŸ§ª Quality & Accuracy

### v1.0 Baseline Metrics
- **Exact matches:** 0% (on 20-specimen validation)
- **Partial matches:** ~10-15%
- **ScientificName coverage:** 5.5% (159/2,885 specimens)
- **CatalogNumber coverage:** 50%
- **Known limitations:** OCR accuracy on handwritten labels

### v2.0 Expected Improvements
- **Quality:** ~70% accuracy (layout-aware prompts)
- **Coverage:** 16 fields vs 7
- **Spatial understanding:** TOP (catalogNumber) vs BOTTOM (collection data) distinction

**âš ï¸ All extracted data should be manually reviewed before publication**

## ğŸ¯ Use Cases

### âœ… When to Use This Tool
- Digitizing physical herbarium collections
- Creating GBIF-ready biodiversity datasets
- Batch processing specimen photographs
- Extracting structured data from label images

### âŒ Not Suitable For
- Live plant identification (use iNaturalist)
- Specimens without readable labels
- Real-time field data collection

## ğŸ“š Documentation

### Getting Started
- [Quick Start Guide](README.md#quick-start)
- [Installation](README.md#installation)
- [API Setup](API_SETUP_QUICK.md)

### Advanced Topics
- [Agent Orchestration Framework](agents/README.md)
- [Data Publication Strategy](docs/DATA_PUBLICATION_GUIDE.md)
- [Scientific Provenance Pattern](docs/SCIENTIFIC_PROVENANCE_PATTERN.md) â­ **NEW**
- [Configuration Guide](docs/configuration.md)
- [Development Guide](docs/development.md)

### Reference
- [API Documentation](docs/api_reference.md)
- [Database Schema](docs/database_schema.md)
- [Troubleshooting](docs/troubleshooting.md)
- [FAQ](docs/faq.md)

## ğŸ”„ Processing Workflow

```mermaid
graph LR
    A[Image] --> B[OCR Engine]
    B --> C[Text Extraction]
    C --> D[Rules Engine]
    D --> E[Darwin Core]
    E --> F[Review Interface]
    F --> G[GBIF Export]
```

### Step-by-Step

1. **Prepare images** in a directory
2. **Run extraction:** `python cli.py process --input photos/ --output results/`
3. **Review results:** Web or terminal interface
4. **Export data:** Darwin Core CSV ready for GBIF

## ğŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Install dev dependencies
uv sync --all-extras

# Run tests
pytest

# Lint code
ruff check . --fix
```

## ğŸ“‹ System Requirements

- **Python:** 3.11 or higher
- **Disk space:** ~1GB for dependencies, ~5GB for image cache
- **Memory:** 4GB minimum (8GB recommended for large batches)
- **OS:** macOS (best), Linux, Windows

## ğŸ”– Version History

**Current:** v1.0.0 (October 2025)
**Previous:** v1.0.0-beta.2 (Storage abstraction layer)

See [CHANGELOG.md](CHANGELOG.md) for full version history.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™‹ Support

- **Issues:** [GitHub Issues](https://github.com/devvyn/aafc-herbarium-dwc-extraction-2025/issues)
- **Documentation:** [docs/](docs/)
- **Examples:** [docs/workflow_examples.md](docs/workflow_examples.md)

## ğŸ† Project Status

**Production Ready** âœ…
- âœ… 2,885 specimens extracted (v1.0 baseline)
- âœ… Ground truth validation complete
- âœ… GBIF publication workflow documented
- ğŸ”„ v2.0 enhanced extraction in progress
- ğŸ”„ Agent orchestration framework complete

---

**Built for Agriculture and Agri-Food Canada (AAFC)**
*Enabling biodiversity data digitization at scale*
