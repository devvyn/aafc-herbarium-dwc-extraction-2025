"""Language code normalization helpers."""

from __future__ import annotations

from typing import Iterable, List

# ISO 639-1/639-2 mappings derived from
# https://github.com/datasets/language-codes (MIT Licensed).
# Embedded to avoid runtime dependency on external datasets.

_ISO3_TO_ISO2 = {
    'aar': 'aa',
    'abk': 'ab',
    'afr': 'af',
    'aka': 'ak',
    'alb': 'sq',
    'amh': 'am',
    'ara': 'ar',
    'arg': 'an',
    'arm': 'hy',
    'asm': 'as',
    'ava': 'av',
    'ave': 'ae',
    'aym': 'ay',
    'aze': 'az',
    'bak': 'ba',
    'bam': 'bm',
    'baq': 'eu',
    'bel': 'be',
    'ben': 'bn',
    'bis': 'bi',
    'bod': 'bo',
    'bos': 'bs',
    'bre': 'br',
    'bul': 'bg',
    'bur': 'my',
    'cat': 'ca',
    'ces': 'cs',
    'cha': 'ch',
    'che': 'ce',
    'chi': 'zh',
    'chu': 'cu',
    'chv': 'cv',
    'cor': 'kw',
    'cos': 'co',
    'cre': 'cr',
    'cym': 'cy',
    'cze': 'cs',
    'dan': 'da',
    'deu': 'de',
    'div': 'dv',
    'dut': 'nl',
    'dzo': 'dz',
    'ell': 'el',
    'eng': 'en',
    'epo': 'eo',
    'est': 'et',
    'esp': 'es',
    'eus': 'eu',
    'ewe': 'ee',
    'fao': 'fo',
    'fas': 'fa',
    'fij': 'fj',
    'fin': 'fi',
    'fra': 'fr',
    'fre': 'fr',
    'fry': 'fy',
    'ful': 'ff',
    'geo': 'ka',
    'ger': 'de',
    'gla': 'gd',
    'gle': 'ga',
    'glg': 'gl',
    'glv': 'gv',
    'gre': 'el',
    'grn': 'gn',
    'guj': 'gu',
    'hat': 'ht',
    'hau': 'ha',
    'heb': 'he',
    'her': 'hz',
    'hin': 'hi',
    'hmo': 'ho',
    'hrv': 'hr',
    'hun': 'hu',
    'hye': 'hy',
    'ibo': 'ig',
    'ice': 'is',
    'ido': 'io',
    'iii': 'ii',
    'iku': 'iu',
    'ile': 'ie',
    'ina': 'ia',
    'ind': 'id',
    'ipk': 'ik',
    'isl': 'is',
    'ita': 'it',
    'jav': 'jv',
    'jpn': 'ja',
    'kal': 'kl',
    'kan': 'kn',
    'kas': 'ks',
    'kat': 'ka',
    'kau': 'kr',
    'kaz': 'kk',
    'khm': 'km',
    'kik': 'ki',
    'kin': 'rw',
    'kir': 'ky',
    'kom': 'kv',
    'kon': 'kg',
    'kor': 'ko',
    'kua': 'kj',
    'kur': 'ku',
    'lao': 'lo',
    'lat': 'la',
    'lav': 'lv',
    'lim': 'li',
    'lin': 'ln',
    'lit': 'lt',
    'ltz': 'lb',
    'lub': 'lu',
    'lug': 'lg',
    'mac': 'mk',
    'mah': 'mh',
    'mal': 'ml',
    'mao': 'mi',
    'mar': 'mr',
    'may': 'ms',
    'mkd': 'mk',
    'mlg': 'mg',
    'mlt': 'mt',
    'mon': 'mn',
    'mri': 'mi',
    'msa': 'ms',
    'mya': 'my',
    'nau': 'na',
    'nav': 'nv',
    'nbl': 'nr',
    'nde': 'nd',
    'ndo': 'ng',
    'nep': 'ne',
    'nld': 'nl',
    'nno': 'nn',
    'nob': 'nb',
    'nor': 'no',
    'nya': 'ny',
    'oci': 'oc',
    'oji': 'oj',
    'ori': 'or',
    'orm': 'om',
    'oss': 'os',
    'pan': 'pa',
    'per': 'fa',
    'pli': 'pi',
    'pol': 'pl',
    'por': 'pt',
    'pus': 'ps',
    'que': 'qu',
    'roh': 'rm',
    'ron': 'ro',
    'rum': 'ro',
    'run': 'rn',
    'rus': 'ru',
    'sag': 'sg',
    'san': 'sa',
    'sin': 'si',
    'slk': 'sk',
    'slo': 'sk',
    'slv': 'sl',
    'sme': 'se',
    'smo': 'sm',
    'sna': 'sn',
    'snd': 'sd',
    'som': 'so',
    'sot': 'st',
    'spa': 'es',
    'sqi': 'sq',
    'srd': 'sc',
    'srp': 'sr',
    'ssw': 'ss',
    'sun': 'su',
    'swa': 'sw',
    'swe': 'sv',
    'tah': 'ty',
    'tam': 'ta',
    'tat': 'tt',
    'tel': 'te',
    'tgk': 'tg',
    'tgl': 'tl',
    'tha': 'th',
    'tib': 'bo',
    'tir': 'ti',
    'ton': 'to',
    'tsn': 'tn',
    'tso': 'ts',
    'tuk': 'tk',
    'tur': 'tr',
    'twi': 'tw',
    'uig': 'ug',
    'ukr': 'uk',
    'urd': 'ur',
    'uzb': 'uz',
    'ven': 've',
    'vie': 'vi',
    'vol': 'vo',
    'wel': 'cy',
    'wln': 'wa',
    'wol': 'wo',
    'xho': 'xh',
    'yid': 'yi',
    'yor': 'yo',
    'zha': 'za',
    'zho': 'zh',
    'zul': 'zu',
}

_ISO2_TO_ISO3 = {
    'aa': 'aar',
    'ab': 'abk',
    'ae': 'ave',
    'af': 'afr',
    'ak': 'aka',
    'am': 'amh',
    'an': 'arg',
    'ar': 'ara',
    'as': 'asm',
    'av': 'ava',
    'ay': 'aym',
    'az': 'aze',
    'ba': 'bak',
    'be': 'bel',
    'bg': 'bul',
    'bi': 'bis',
    'bm': 'bam',
    'bn': 'ben',
    'bo': 'bod',
    'br': 'bre',
    'bs': 'bos',
    'ca': 'cat',
    'ce': 'che',
    'ch': 'cha',
    'co': 'cos',
    'cr': 'cre',
    'cs': 'ces',
    'cu': 'chu',
    'cv': 'chv',
    'cy': 'cym',
    'da': 'dan',
    'de': 'deu',
    'dv': 'div',
    'dz': 'dzo',
    'ee': 'ewe',
    'el': 'ell',
    'en': 'eng',
    'eo': 'epo',
    'es': 'spa',
    'et': 'est',
    'eu': 'eus',
    'fa': 'fas',
    'ff': 'ful',
    'fi': 'fin',
    'fj': 'fij',
    'fo': 'fao',
    'fr': 'fra',
    'fy': 'fry',
    'ga': 'gle',
    'gd': 'gla',
    'gl': 'glg',
    'gn': 'grn',
    'gu': 'guj',
    'gv': 'glv',
    'ha': 'hau',
    'he': 'heb',
    'hi': 'hin',
    'ho': 'hmo',
    'hr': 'hrv',
    'ht': 'hat',
    'hu': 'hun',
    'hy': 'hye',
    'hz': 'her',
    'ia': 'ina',
    'id': 'ind',
    'ie': 'ile',
    'ig': 'ibo',
    'ii': 'iii',
    'ik': 'ipk',
    'io': 'ido',
    'is': 'isl',
    'it': 'ita',
    'iu': 'iku',
    'ja': 'jpn',
    'jv': 'jav',
    'ka': 'kat',
    'kg': 'kon',
    'ki': 'kik',
    'kj': 'kua',
    'kk': 'kaz',
    'kl': 'kal',
    'km': 'khm',
    'kn': 'kan',
    'ko': 'kor',
    'kr': 'kau',
    'ks': 'kas',
    'ku': 'kur',
    'kv': 'kom',
    'kw': 'cor',
    'ky': 'kir',
    'la': 'lat',
    'lb': 'ltz',
    'lg': 'lug',
    'li': 'lim',
    'ln': 'lin',
    'lo': 'lao',
    'lt': 'lit',
    'lu': 'lub',
    'lv': 'lav',
    'mg': 'mlg',
    'mh': 'mah',
    'mi': 'mri',
    'mk': 'mkd',
    'ml': 'mal',
    'mn': 'mon',
    'mr': 'mar',
    'ms': 'msa',
    'mt': 'mlt',
    'my': 'mya',
    'na': 'nau',
    'nb': 'nob',
    'nd': 'nde',
    'ne': 'nep',
    'ng': 'ndo',
    'nl': 'nld',
    'nn': 'nno',
    'no': 'nor',
    'nr': 'nbl',
    'nv': 'nav',
    'ny': 'nya',
    'oc': 'oci',
    'oj': 'oji',
    'om': 'orm',
    'or': 'ori',
    'os': 'oss',
    'pa': 'pan',
    'pi': 'pli',
    'pl': 'pol',
    'ps': 'pus',
    'pt': 'por',
    'qu': 'que',
    'rm': 'roh',
    'rn': 'run',
    'ro': 'ron',
    'ru': 'rus',
    'rw': 'kin',
    'sa': 'san',
    'sc': 'srd',
    'sd': 'snd',
    'se': 'sme',
    'sg': 'sag',
    'si': 'sin',
    'sk': 'slk',
    'sl': 'slv',
    'sm': 'smo',
    'sn': 'sna',
    'so': 'som',
    'sq': 'sqi',
    'sr': 'srp',
    'ss': 'ssw',
    'st': 'sot',
    'su': 'sun',
    'sv': 'swe',
    'sw': 'swa',
    'ta': 'tam',
    'te': 'tel',
    'tg': 'tgk',
    'th': 'tha',
    'ti': 'tir',
    'tk': 'tuk',
    'tl': 'tgl',
    'tn': 'tsn',
    'to': 'ton',
    'tr': 'tur',
    'ts': 'tso',
    'tt': 'tat',
    'tw': 'twi',
    'ty': 'tah',
    'ug': 'uig',
    'uk': 'ukr',
    'ur': 'urd',
    'uz': 'uzb',
    've': 'ven',
    'vi': 'vie',
    'vo': 'vol',
    'wa': 'wln',
    'wo': 'wol',
    'xh': 'xho',
    'yi': 'yid',
    'yo': 'yor',
    'za': 'zha',
    'zh': 'zho',
    'zu': 'zul',
}


def to_iso2(lang: str) -> str:
    """Return the ISO 639-1 code for ``lang``.

    Accepts ISO 639-1 or 639-2 codes and normalizes to lower-case
    two-letter tags. Raises ``ValueError`` when no mapping exists.
    """

    code = lang.strip().lower()
    if len(code) == 2 and code.isalpha():
        return code
    if len(code) == 3 and code.isalpha():
        try:
            return _ISO3_TO_ISO2[code]
        except KeyError as exc:
            raise ValueError(f"Unsupported ISO 639-2 code: {lang}") from exc
    raise ValueError(f"Unsupported language code: {lang}")


def to_iso3(lang: str) -> str:
    """Return the ISO 639-2/T code for ``lang``.

    Accepts ISO 639-1 or 639-2 codes and normalizes to lower-case
    three-letter tags. Raises ``ValueError`` when no mapping exists.
    """

    code = lang.strip().lower()
    if len(code) == 3 and code.isalpha():
        return code
    if len(code) == 2 and code.isalpha():
        try:
            return _ISO2_TO_ISO3[code]
        except KeyError as exc:
            raise ValueError(f"Unsupported ISO 639-1 code: {lang}") from exc
    raise ValueError(f"Unsupported language code: {lang}")


def normalize_iso2(langs: Iterable[str]) -> List[str]:
    """Normalize language codes to ISO 639-1."""

    return [to_iso2(lang) for lang in langs]


def normalize_iso3(langs: Iterable[str]) -> List[str]:
    """Normalize language codes to ISO 639-2/T."""

    return [to_iso3(lang) for lang in langs]


__all__ = ['to_iso2', 'to_iso3', 'normalize_iso2', 'normalize_iso3']
